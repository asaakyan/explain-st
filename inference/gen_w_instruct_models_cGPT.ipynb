{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from time import sleep\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")  # for exponential backoff\n",
    "\n",
    "openai.api_key = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def evaluate(input, instruction=None, fs_prompt=None, \n",
    "             verbose=False):\n",
    "    prompt = generate_prompt(input, instruction, fs_prompt)\n",
    "    if verbose: \n",
    "        print(\"****PROMPT:****\")\n",
    "        print(prompt)\n",
    "        print(\"****END PROMPT****\")\n",
    "    messages = [{'role': 'user',\n",
    "                 'content': prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "      model=\"gpt-3.5-turbo-0301\",\n",
    "      messages=messages,\n",
    "      temperature=0.7,\n",
    "      top_p=0.9\n",
    "    )\n",
    "    # print(response)\n",
    "    # print(\"*\"*20)\n",
    "    result = ''\n",
    "    for choice in response.choices:\n",
    "        result += choice.message.content.strip()\n",
    "    return result.strip(), response['usage']['total_tokens']\n",
    "\n",
    "def construct_few_shot_prompt(train_file_path, n=10):\n",
    "    # prompt = \"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\"\n",
    "    # sample 10 instances from train.json\n",
    "    with open(train_file_path, \"r\") as f:\n",
    "        train_samples = json.load(f)\n",
    "        train_samples = train_samples[:n]\n",
    "    for i, row in enumerate(train_samples):\n",
    "        instruction, input, response = row[\"instruction\"], row[\"input\"], row[\"output\"]\n",
    "        if i ==0: prompt = f\"\"\"{instruction}\\nFor example:\\n\"\"\"\n",
    "        prompt += f\"\"\"{input}\n",
    "{response}\n",
    "\n",
    "\"\"\"\n",
    "    prompt = f\"{prompt}For the following sentence, {instruction.lower()}\"\n",
    "    return prompt.strip()\n",
    "\n",
    "def generate_prompt(input, instruction=None, fs_prompt=None):\n",
    "    if input and instruction:\n",
    "        return f\"\"\"{instruction}\n",
    "{input}\"\"\"\n",
    "    if input and fs_prompt:\n",
    "        return f\"\"\"{fs_prompt}\n",
    "        \n",
    "{input}\"\"\"\n",
    "\n",
    "def run_inference(input_json, out_dir,\n",
    "                   model_name, \n",
    "                   n_shots = True, train_file_path=None,\n",
    "                   verbose=False, stop_idx=10000):\n",
    "    \n",
    "    output = []\n",
    "    with open( input_json,'r') as fp:\n",
    "        test_file = json.load(fp)\n",
    "\n",
    "    total_tokens = 0\n",
    "    for i, line in enumerate(test_file):\n",
    "        if i > stop_idx: break\n",
    "\n",
    "        print(f\"INSTANCE {i}, percentage: {i/len(test_file)}\")\n",
    "        print(f\"INSTRUCTION: {line['instruction']}\\nINPUT: {line['input']}\\n\")\n",
    "\n",
    "        if n_shots == 0:\n",
    "            pred = evaluate(input=line['input'], instruction=line['instruction'], \n",
    "                            verbose=verbose)\n",
    "        else:\n",
    "            fs_prompt = construct_few_shot_prompt(train_file_path, n=n_shots)\n",
    "            pred, tokens = evaluate(input=line['input'], fs_prompt=fs_prompt,\n",
    "                            verbose=verbose)\n",
    "            total_tokens += tokens\n",
    "            print(f\"CURRENT_TOTAL_COST: {(total_tokens/1000)*0.002}\\n\")\n",
    "        output += [{\"instruction\": line['instruction'],\n",
    "                \"input\": line['input'],\n",
    "                \"pred\": pred,\n",
    "                \"id\": i\n",
    "                }]\n",
    "        \n",
    "        print(\"RESPONSE:\\n\", pred)\n",
    "        print(\"-\"*50)\n",
    "\n",
    "        if i%10==0:\n",
    "            with open(f\"{out_dir}/{model_name}_test_output.json\",'w', encoding='utf-8') as fp:\n",
    "                json.dump(output, fp, indent=4)\n",
    "    # final save\n",
    "    with open(f\"{out_dir}/{model_name}_test_output.json\",'w', encoding='utf-8') as fp:\n",
    "            json.dump(output, fp, indent=4)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"../data/gyafc_w_ICHF_alpaca/informal_to_formal\"\n",
    "assert os.path.isdir(out_dir)\n",
    "input_json = \"../data/gyafc_w_ICHF_alpaca/informal_to_formal/test.json\"\n",
    "assert os.path.isfile(input_json)\n",
    "train_file_path = \"../data/gyafc_w_ICHF_alpaca/informal_to_formal/train.json\"\n",
    "assert os.path.isfile(train_file_path)\n",
    "\n",
    "# fs_prompt = construct_few_shot_prompt(train_file_path, n=3)\n",
    "# print(generate_prompt(input=\"test\", fs_prompt=fs_prompt))\n",
    "\n",
    "run_inference(input_json, out_dir, \n",
    "              \"chatGPT\",\n",
    "              n_shots=1, train_file_path=train_file_path,\n",
    "              verbose=False, stop_idx=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"../data/gyafc_w_ICHF_alpaca/formal_to_informal\"\n",
    "assert os.path.isdir(out_dir)\n",
    "input_json = \"../data/gyafc_w_ICHF_alpaca/formal_to_informal/test.json\"\n",
    "assert os.path.isfile(input_json)\n",
    "train_file_path = \"../data/gyafc_w_ICHF_alpaca/formal_to_informal/train.json\"\n",
    "assert os.path.isfile(train_file_path)\n",
    "\n",
    "run_inference(input_json, out_dir, \n",
    "              \"chatGPT\",\n",
    "              n_shots=1, train_file_path=train_file_path,\n",
    "              verbose=False, stop_idx=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpaca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
